---
title: "R Notebook"
output: html_notebook
---

Request from Andy Dunstan on the following problem.

Email from AD on Feb 24, 2020:

Here is another query for your advice if you have the time and inclination – much appreciated if you do. It’s another one of those limited data situations where there is a good time series but limited number of logger locations available. Am wondering if this may suit a statistical model similar to the limited sample data points available for hatchling counts?

We wish to determine a best fit maximum inundation curve (berm to back swale across the beach) for months of Dec, Jan, Feb and March if possible. At the moment the model used is the best fit regression curve from peak inundation data at each logger location. The distance of logger locations from the berm does change with island shifts and changes to the berm over season and years and has been measured with dGPS surveys. This provides a range of slightly different logger-berm distance points to use and hopefully increases the confidence levels in a calculated curve. However …. am hoping there may be a better method to fit the curve and provide confidence limits or if this is indeed the best model then a good suggestion for statistical justification of this curve?

This curve would then be correlated with nest locations (distance from berm) and elevations (calculated from the curve where x-axis is distance from berm) to infer inundation from the curve. (eg. Above top of nest, marginal to level of middle of nest or no inundation as three categories). Data suggests some variation in inundation curve profiles around the island at the four different transects however not too radical. There is a definite outlier to this in the NW (mooring) beach area when Westerly winds have lowered the berm and peak tide levels are above this berm height resulting in inundation across the entire beach width – can be treated separately.

End of AD's email.

Additionally, the original request is from Owen Coffee:

The intention in this workbook is to define a predicted monthly max inundation curve for the whole of island based on the inundation data from the loggers at the 4 transects around the beach. At present the produced predicted curves are the log. Regression of the max inundation points for each month ± a 95% conf. interval. The relationships between the curves however are variable which look to be related to sample size and variation between sectors. Having defined these predicted inundation curves the marked nests are then plotted against these predictions and any nest with the 95% conf. interval or below the inundation height is predicted to have been inundated. The intention is then to review the hatching success and development phases of failed eggs for these nests identified as inundated to determine whether the predicted inundation events correlate with the phases of failed eggs.

Any comments/suggestions on improvements in determining the best regression model to fit the different months or potentially an improved method to define a predicted monthly max inundation curve which allows smoothing of the produced curve, and whether it possible to automate the identification of inundated nests (as this process is currently manual) would be greatly appreciated.

End of OC's email

First, as usual, I look at the data in different ways.

Load essential libraries first.

```{r}
rm(list=ls())
library(ggplot2)
library(tidyverse)
library(readr)
library(lubridate)
library(jagsUI)
library(bayesplot)

# a function to extract posterior samples from jags output
extract.samples <- function(varname, zm){
  dev <- unlist(lapply(zm, FUN = function(x) x[, varname]))
  return(dev)
}

# A function to find 95% CI for predictions
extract.prediction <- function(zm, jags.data){
  if (length(grep("n.transects", names(jags.data))) > 0){
    length.b <- jags.data$n.transects
  } else if (length(grep("n.months", names(jags.data))) > 0){
    length.b <- jags.data$n.months
  }
  
  b0 <- b1 <- b12 <- vector(mode = "list", length = length.b)
  k <- 1
  for (k in 1:length.b){
    b0[[k]] <- extract.samples(paste0("b0[", k, "]"), zm$samples)
    b1[[k]] <- extract.samples(paste0("b1[", k, "]"), zm$samples)
    
    # in case of poly2
    if (length(grep("b12", unlist(dimnames(zm$samples[[1]])))) > 0){
      b12[[k]] <- extract.samples(paste0("b12[", k, "]"), zm$samples)
    } else {
      b12[[k]] <- rep(0, length(b0[[k]]))
    }
  }
  length.year <- jags.data$n.years
  
  b2 <- vector(mode = "list", length = length.year)
  for (k in 1:length.year){
    b2[[k]] <- extract.samples(paste0("b2[", k, "]"), zm$samples)
  }
  
  Dvec <- seq(0, 80, by = 1)  # min and max of Distance from Berm
  Yvec <- seq(1, length.year)
  
  pred.Y <- vector(mode = "list", length = (length.year * length.b))
  k <- y <- c <- 1
  for (k in 1:length.b){      # transects/months
    for (y in 1:length.year){    # years
      pred.Y[[c]] <- b0[[k]] + b1[[k]] %*% t(Dvec) + 
        b12[[k]] %*% t(Dvec^2) + b2[[y]] * Yvec[y]
      
      c <- c + 1
    }
    
  }
  
  coefs <- c(b0, b1, b12, b2)
  # get quantiles
  
  qtiles <- lapply(pred.Y, 
                   FUN = function(x) apply(x, MARGIN = 2, 
                                           FUN = quantile, c(0.025, 0.5, 0.975)))
  
  qtiles.mat <- data.frame(do.call(rbind, lapply(qtiles, FUN = t)))
  
  year.vec <- rep(rep(seq(1, length.year), 
                      each = length(Dvec)), 
                  length.b)
  
  b.vec <- rep(seq(1, length.b), each = length(Dvec) * length(Yvec))

  if (length(grep("n.transects", names(jags.data))) > 0){
    pred.df <- data.frame(Transect_f = as.factor(b.vec + 1), 
                          Year = year.vec + 2017, 
                          Dist_Berm = rep(Dvec, length.b * length(Yvec)),
                          pred_low = qtiles.mat$X2.5., 
                          pred_med = qtiles.mat$X50., 
                          pred_high = qtiles.mat$X97.5.)
  } else if (length(grep("n.months", names(jags.data))) > 0){
    pred.df <- data.frame(Month2 = b.vec, 
                          Year = year.vec + 2017, 
                          Dist_Berm = rep(Dvec, length.b * length(Yvec)),
                          pred_low = qtiles.mat$X2.5., 
                          pred_med = qtiles.mat$X50., 
                          pred_high = qtiles.mat$X97.5.)

  }

  out.list <- list(pred.df = pred.df,
                   coefs = coefs)
  
  return(out.list)
}

```

And load the data.

```{r}

inund.cols <- cols(
   Transect = col_double(),
   Post = col_double(),
   InundHeight_AbvLAT = col_double(),
   Dist_Berm = col_double(),
   Berm_elevation = col_double(),
   BermSurvey_Month = col_character(),
   Inund_Month = col_character(),
   Date = col_date(format = "%d/%m/%Y"),
   Time = col_time(format = "%H:%M:%S %p"))

inund <- read_csv("data/inundationRaine.csv", col_types = inund.cols)
#View(inund)

nestmap.cols <- cols(
     Nest_ID = col_double(),
     Nest_Easting = col_double(),
     Nest_Northing = col_double(),
     Nest_Elevation = col_double(),
     BermDist_m = col_double())

Nest_18Map <- read_csv("data/2018Nest_mapping.csv", col_types = nestmap.cols)
#View(Nest_18Map)

nest18.cols <- cols(
   Nest_ID = col_double(),
   Nest_Easting = col_double(),
   Nest_Northing = col_double(),
   Nest_Elevation = col_double(),
   BermDist_m = col_double(),
   inundated = col_character())
Nest_18INUND <- read_csv("data/2018Nest_INUND.csv", col_types = nest18.cols)
```


Make some plots:

```{r}
ggplot() + 
  geom_point(data = inund,
             aes(x = Dist_Berm,
                 y = InundHeight_AbvLAT,
                 color = Inund_Month,
                 shape = as.factor(Transect)))
```

And in the log scale:

```{r}
ggplot() + 
  geom_point(data = inund,
             aes(x = Dist_Berm,
                 y = log(InundHeight_AbvLAT),
                 color = Inund_Month,
                 shape = as.factor(Transect)))
```

Even at the log scale, some don't look linear (e.g., transect 5 (crosses)). Take a look at them more closely.  First, split them into two years.

```{r}
inund %>% mutate(Year = ifelse(Date < as.Date("2018-05-01"), 2018, 2019)) %>%
  mutate(Month = month(Date)) %>%
  mutate(Transect_f = as.factor(Transect)) -> inund

inund.2018 <- filter(inund, Year == 2018)
inund.2019 <- filter(inund, Year == 2019)

```

Then plot one year at a time.

```{r}
ggplot() + 
  geom_point(data = inund.2018,
             aes(x = Dist_Berm,
                 y = log(InundHeight_AbvLAT),
                 color = as.factor(Month),
                 shape = Transect_f))
```


```{r}
ggplot() + 
  geom_point(data = inund.2019,
             aes(x = Dist_Berm,
                 y = log(InundHeight_AbvLAT),
                 color = as.factor(Month),
                 shape = as.factor(Transect)))
```

I think non-linear models (or polynomial) are probably better than linear models...  

```{r}
ggplot() + 
  geom_point(data = inund.2018,
             aes(x = Dist_Berm,
                 y = log(InundHeight_AbvLAT),
                 color = as.factor(Month))) +
  facet_wrap(~ Transect_f, nrow = 2)  
  #geom_smooth(method = "loess", size = 1.5)    # this doesn't work - too small sample size

# ggsave(filename = "figures/InundHeight_2018.png",
#        device = "png", dpi = 600)
```

```{r}
ggplot() + 
  geom_point(data = inund.2019,
             aes(x = Dist_Berm,
                 y = log(InundHeight_AbvLAT),
                 color = as.factor(Month))) +
  #facet_grid(. ~ Transect_f) +
  facet_wrap(~ Transect_f, nrow = 2)

# ggsave(filename = "figures/InundHeight_2019.png",
#        device = "png", dpi = 600)
```

When I add Berm_elevation, variability decreases... maybe on to something? 

```{r}
ggplot() + 
  geom_point(data = inund.2018,
             aes(x = Dist_Berm,
                 y = log(InundHeight_AbvLAT + Berm_elevation),
                 color = as.factor(Month))) +
  #facet_grid(. ~ Transect_f) +
  facet_wrap(~ Transect_f, nrow = 2)

# ggsave(filename = "figures/InundHeight_Berm_2018.png",
#        device = "png", dpi = 600)
```



```{r}
ggplot() + 
  geom_point(data = inund.2019,
             aes(x = Dist_Berm,
                 y = log(InundHeight_AbvLAT + Berm_elevation),
                 color = as.factor(Month))) +
  #facet_grid(. ~ Transect_f) +
  facet_wrap(~ Transect_f, nrow = 2)

# ggsave(filename = "figures/InundHeight_Berm_2019.png",
#        device = "png", dpi = 600)
```

We should be able to have a model that is fitted to all transects but each transect having its slope and intercept (random slope and intercept). 

Change transects and months

```{r}
ggplot() + 
  geom_point(data = inund.2018,
             aes(x = Dist_Berm,
                 y = log(InundHeight_AbvLAT),
                 color = Transect_f)) + 
  #facet_grid(. ~ Transect_f) +
  facet_wrap(~ Month, nrow = 3)

```

```{r}
ggplot() + 
  geom_point(data = inund.2019,
             aes(x = Dist_Berm,
                 y = log(InundHeight_AbvLAT),
                 color = Transect_f)) + 
  #facet_grid(. ~ Transect_f) +
  facet_wrap(~ Month, nrow = 3)

```

Variability among transects is quite small in some cases, maybe except transect 2 in 2019.


First, transform some variables:

```{r}
inund %>% mutate(Year2 = ifelse(Year == 2018, 1, 2),
                 Month2 = ifelse(Month > 9, Month - 9, Month + 3),
                 Transect2 = Transect - 1,
                 log_inund = log(InundHeight_AbvLAT)) -> inund


```


Fit the first model:
```{r}

jags.data <- list(y = inund$log_inund,
                  month = inund$Month2,
                  Dist_Berm = inund$Dist_Berm,
                  year = inund$Year2,
                  N = nrow(inund),
                  n.months = length(unique(inund$Month2)),
                  n.years = length(unique(inund$Year2)))

MCMC.params <- list(n.samples = 10000,
                    n.burnin = 5000,
                    n.thin = 5,
                    n.chains = 5)

parameters <- c("b0", "b1", "b2", "sigma.y", "deviance")

MCMC.params$model.file = "models/Model_linear_month_year.txt"

#if (!file.exists("RData/linear_month_year.rds")){
  jm.1 <- jags(data = jags.data,
             #inits = inits,
             parameters.to.save= parameters,
             model.file = MCMC.params$model.file,
             n.chains = MCMC.params$n.chains,
             n.burnin = MCMC.params$n.burnin,
             n.thin = MCMC.params$n.thin,
             n.iter = MCMC.params$n.samples,
             DIC = T, 
             parallel=T)

#   saveRDS(jm, file = "RData/linear_month_year.rds")  
# } else {
#   jm <- readRDS("RData/linear_month_year.rds")
# }

summary(jm.1)  

# check some posteriors
mcmc_trace(jm.1$samples, pars = c("b0[1]", "b0[2]", "b0[3]", "b0[4]"))
mcmc_trace(jm.1$samples, pars = c("b1[1]", "b1[2]", "b1[3]", "b1[4]"))
mcmc_trace(jm.1$samples, pars = c("b2[1]", "b2[2]"))
```

Extract the posterior samples and create plots
```{r}
pred.list.jm.1 <- extract.prediction(zm = jm.1, jags.data = jags.data)

pred.list.jm.1$pred.df %>% mutate(Month = ifelse(Month2 < 4, Month2 + 9, Month2 - 3)) -> pred.df.jm.1

pred.df.jm.1 %>% filter(Year == 2018) -> pred.df.jm.1.2018
ggplot() + 
  geom_point(data = inund.2018,
             aes(x = Dist_Berm,
                 y = log(InundHeight_AbvLAT))) +
  geom_path(data = pred.df.jm.1.2018,
            aes(x = Dist_Berm,
                 y = (pred_med))) +
  geom_ribbon(data = pred.df.jm.1.2018,
              aes(x = Dist_Berm,
                  ymin = (pred_low),
                  ymax = (pred_high)),
              alpha = 0.5) +
  facet_wrap(~ Month, nrow = 2)  

```

```{r}

pred.df.jm.1 %>% filter(Year == 2019) -> pred.df.jm.1.2019
ggplot() + 
  geom_point(data = inund.2019,
             aes(x = Dist_Berm,
                 y = log(InundHeight_AbvLAT))) +
  geom_path(data = pred.df.jm.1.2019,
            aes(x = Dist_Berm,
                 y = (pred_med))) +
  geom_ribbon(data = pred.df.jm.1.2019,
              aes(x = Dist_Berm,
                  ymin = (pred_low),
                  ymax = (pred_high)),
              alpha = 0.5) +
  facet_wrap(~ Month, nrow = 2)  

```

I think the second-order polynomial may fit better... Let's try...

```{r}
MCMC.params$model.file = "models/Model_Poly2_month_year.txt"

parameters <- c("b0", "b1", "b2", "b12", "sigma.y", "deviance")

#if (!file.exists("RData/linear_Poly2_month_year.rds")){
  jm.2 <- jags(data = jags.data,
             #inits = inits,
             parameters.to.save= parameters,
             model.file = MCMC.params$model.file,
             n.chains = MCMC.params$n.chains,
             n.burnin = MCMC.params$n.burnin,
             n.thin = MCMC.params$n.thin,
             n.iter = MCMC.params$n.samples,
             DIC = T, 
             parallel=T)

#   saveRDS(jm.2, file = "RData/linear_Poly2_month_year.rds")  
# } else {
#   jm.2 <- readRDS("RData/linear_Poly2_month_year.rds")
# }

summary(jm.2)  

# check some posteriors
mcmc_trace(jm.2$samples, pars = c("b0[1]", "b0[2]", "b0[3]", "b0[4]"))
mcmc_trace(jm.2$samples, pars = c("b1[1]", "b1[2]", "b1[3]", "b1[4]",
                                "b1[5]", "b1[6]", "b1[7]"))
mcmc_trace(jm.2$samples, pars = c("b12[1]", "b12[2]", "b12[3]", "b12[4]",
                                "b12[5]", "b12[6]", "b12[7]"))
mcmc_trace(jm.2$samples, pars = c("b2[1]", "b2[2]"))
```

Extract the posterior samples and create plots
```{r}
pred.list.jm.2 <- extract.prediction(zm = jm.2, jags.data = jags.data)

pred.list.jm.2$pred.df %>% mutate(Month = ifelse(Month2 < 4, Month2 + 9, Month2 - 3)) -> pred.df.jm.2

pred.df.jm.2 %>% filter(Year == 2018) -> pred.df.jm.2.2018
ggplot() + 
  geom_point(data = inund.2018,
             aes(x = Dist_Berm,
                 y = log(InundHeight_AbvLAT))) +
  geom_path(data = pred.df.jm.2.2018,
            aes(x = Dist_Berm,
                 y = (pred_med))) +
  geom_ribbon(data = pred.df.jm.2.2018,
              aes(x = Dist_Berm,
                  ymin = (pred_low),
                  ymax = (pred_high)),
              alpha = 0.5) +
  facet_wrap(~ Month, nrow = 2)  

```

Of course... the 2nd order polynomial has to increase at the end, which is not good in this case. 


```{r}
pred.df.jm.2 %>% filter(Year == 2019) -> pred.df.jm.2.2019
ggplot() + 
  geom_point(data = inund.2019,
             aes(x = Dist_Berm,
                 y = log(InundHeight_AbvLAT))) +
  geom_path(data = pred.df.jm.2.2019,
            aes(x = Dist_Berm,
                 y = (pred_med))) +
  geom_ribbon(data = pred.df.jm.2.2019,
              aes(x = Dist_Berm,
                  ymin = (pred_low),
                  ymax = (pred_high)),
              alpha = 0.5) +
  facet_wrap(~ Month, nrow = 2)  

```

